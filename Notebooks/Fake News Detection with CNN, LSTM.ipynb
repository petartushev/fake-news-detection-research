{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4c44b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# from nltk import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "#  Sequential,\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Conv1D, Embedding, LSTM, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "#  GRU, Bidirectional\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# from transformers import BertTokenizerFast, TFBertModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "# from transformers import DistilBertTokenizer, TFDistilBertModel\n",
    "\n",
    "# from scripts.word_embeddings import load_embedding_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b829105",
   "metadata": {},
   "source": [
    "# Defining utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "772923bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(word):\n",
    "    return re.sub(r'[\\-\\(\\)\\?\\*\\\\\\'\\\"\\.%\\^,:<>|;!]', '', word.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41402fcc",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7f26a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/petar/Fakultet/Semester 7/NLP/Datasets/fake_news/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13fc315a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(path + 'full_train_df.csv', index_col=0)\n",
    "test = pd.read_csv(path + 'full_test_df.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ed8bac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 29999 entries, 0 to 29998\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   user    29999 non-null  object\n",
      " 1   tweet   29999 non-null  object\n",
      " 2   label   29999 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 937.5+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16097459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fav48xfxollnr5ho5pf5e2489ts2vhll</td>\n",
       "      <td>In light of the Democrats did not have been bo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fav48xfxollnr5ho5pf5e2489ts2vhll</td>\n",
       "      <td>Funny that the people of our people will have ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fav48xfxollnr5ho5pf5e2489ts2vhll</td>\n",
       "      <td>If dummy Bill Kristol has been doing from the ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fav48xfxollnr5ho5pf5e2489ts2vhll</td>\n",
       "      <td>Isn't it sad that on a Twitter rant. She is a ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fav48xfxollnr5ho5pf5e2489ts2vhll</td>\n",
       "      <td>.#USER# Your story about my management style &amp;...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               user  \\\n",
       "0  fav48xfxollnr5ho5pf5e2489ts2vhll   \n",
       "1  fav48xfxollnr5ho5pf5e2489ts2vhll   \n",
       "2  fav48xfxollnr5ho5pf5e2489ts2vhll   \n",
       "3  fav48xfxollnr5ho5pf5e2489ts2vhll   \n",
       "4  fav48xfxollnr5ho5pf5e2489ts2vhll   \n",
       "\n",
       "                                               tweet  label  \n",
       "0  In light of the Democrats did not have been bo...      1  \n",
       "1  Funny that the people of our people will have ...      1  \n",
       "2  If dummy Bill Kristol has been doing from the ...      1  \n",
       "3  Isn't it sad that on a Twitter rant. She is a ...      1  \n",
       "4  .#USER# Your story about my management style &...      1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3df3ea2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    15000\n",
       "1    14999\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e4527cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 19999 entries, 0 to 19998\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   user    19999 non-null  object\n",
      " 1   tweet   19999 non-null  object\n",
      " 2   label   19999 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 625.0+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a530df7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    10000\n",
       "0     9999\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "641bd51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['tweet'] = train['tweet'].apply(lambda x: clean(x))\n",
    "test['tweet'] = test['tweet'].apply(lambda x: clean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d936ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.groupby(['user', 'label'])['tweet'].agg(list).reset_index()\n",
    "test = test.groupby(['user', 'label'])['tweet'].agg(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b92361c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4370/4018911843.py:1: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_sentences = pd.Series.append(train['tweet'].copy(), test['tweet'].copy())\n"
     ]
    }
   ],
   "source": [
    "all_sentences = pd.Series.append(train['tweet'].copy(), test['tweet'].copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d682604",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = all_sentences.reset_index()['tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae68b1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_transformer = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7fdddf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = sentence_transformer.encode(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ea8f90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['embedding'] = np.copy(embeddings[:300, :]).tolist()\n",
    "test['embedding'] = np.copy(embeddings[300:, :]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c98545fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train['embedding'].copy().values\n",
    "y_train = train['label'].copy().values\n",
    "\n",
    "x_test = test['embedding'].copy().values\n",
    "y_test = test['label'].copy().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1dcae6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.append(x_train, x_test)\n",
    "y = np.append(y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9efd46d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([np.array(emb) for emb in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df4613d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.4, shuffle=True, stratify=y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f366c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-03 11:24:25.801330: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-03 11:24:26.640255: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-03 11:24:26.640646: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-03 11:24:26.675855: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-03 11:24:26.716759: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-03 11:24:26.717359: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-03 11:24:26.717817: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-03 11:24:32.537216: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-03 11:24:32.538145: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-03 11:24:32.538952: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-03 11:24:32.552167: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2299 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "x_train_tmp = tf.expand_dims(x_train.copy(), -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a87944",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f134c4f",
   "metadata": {},
   "source": [
    "# Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a84df98",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 384, 128)          4224      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 49152)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                3145792   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,152,129\n",
      "Trainable params: 3,152,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "\n",
    "# model1.add(Input(shape=(x_train.shape[1],1)))\n",
    "\n",
    "model1.add(Conv1D(128, 32, padding='same', activation=tf.keras.layers.LeakyReLU(alpha=.1), input_shape=[384, 1]))\n",
    "\n",
    "model1.add(Flatten())\n",
    "\n",
    "model1.add(Dense(64, activation='relu'))\n",
    "model1.add(Dense(32, activation='relu'))\n",
    "model1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model1.compile(optimizer=Adam(learning_rate=.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9aad5477",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-03 11:25:03.537959: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 - 29s - loss: 0.6921 - accuracy: 0.5233 - 29s/epoch - 2s/step\n",
      "Epoch 2/20\n",
      "19/19 - 0s - loss: 0.6403 - accuracy: 0.6833 - 153ms/epoch - 8ms/step\n",
      "Epoch 3/20\n",
      "19/19 - 0s - loss: 0.5254 - accuracy: 0.7500 - 130ms/epoch - 7ms/step\n",
      "Epoch 4/20\n",
      "19/19 - 0s - loss: 0.4136 - accuracy: 0.8367 - 114ms/epoch - 6ms/step\n",
      "Epoch 5/20\n",
      "19/19 - 0s - loss: 0.3145 - accuracy: 0.9000 - 113ms/epoch - 6ms/step\n",
      "Epoch 6/20\n",
      "19/19 - 0s - loss: 0.2481 - accuracy: 0.8967 - 112ms/epoch - 6ms/step\n",
      "Epoch 7/20\n",
      "19/19 - 0s - loss: 0.1462 - accuracy: 0.9600 - 114ms/epoch - 6ms/step\n",
      "Epoch 8/20\n",
      "19/19 - 0s - loss: 0.1073 - accuracy: 0.9800 - 113ms/epoch - 6ms/step\n",
      "Epoch 9/20\n",
      "19/19 - 0s - loss: 0.0628 - accuracy: 0.9900 - 112ms/epoch - 6ms/step\n",
      "Epoch 10/20\n",
      "19/19 - 0s - loss: 0.0571 - accuracy: 0.9767 - 110ms/epoch - 6ms/step\n",
      "Epoch 11/20\n",
      "19/19 - 0s - loss: 0.0430 - accuracy: 0.9933 - 112ms/epoch - 6ms/step\n",
      "Epoch 12/20\n",
      "19/19 - 0s - loss: 0.0257 - accuracy: 1.0000 - 112ms/epoch - 6ms/step\n",
      "Epoch 13/20\n",
      "19/19 - 0s - loss: 0.0094 - accuracy: 1.0000 - 111ms/epoch - 6ms/step\n",
      "Epoch 14/20\n",
      "19/19 - 0s - loss: 0.0059 - accuracy: 1.0000 - 113ms/epoch - 6ms/step\n",
      "Epoch 15/20\n",
      "19/19 - 0s - loss: 0.0036 - accuracy: 1.0000 - 111ms/epoch - 6ms/step\n",
      "Epoch 16/20\n",
      "19/19 - 0s - loss: 0.0029 - accuracy: 1.0000 - 112ms/epoch - 6ms/step\n",
      "Epoch 17/20\n",
      "19/19 - 0s - loss: 0.0024 - accuracy: 1.0000 - 112ms/epoch - 6ms/step\n",
      "Epoch 18/20\n",
      "19/19 - 0s - loss: 0.0020 - accuracy: 1.0000 - 112ms/epoch - 6ms/step\n",
      "Epoch 19/20\n",
      "19/19 - 0s - loss: 0.0017 - accuracy: 1.0000 - 113ms/epoch - 6ms/step\n",
      "Epoch 20/20\n",
      "19/19 - 0s - loss: 0.0015 - accuracy: 1.0000 - 112ms/epoch - 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2c0952b430>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(x_train_tmp, y_train.reshape(-1,1), epochs=20, batch_size=16, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80b4d7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 23ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.59      0.61       100\n",
      "           1       0.61      0.64      0.62       100\n",
      "\n",
      "    accuracy                           0.61       200\n",
      "   macro avg       0.62      0.61      0.61       200\n",
      "weighted avg       0.62      0.61      0.61       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model1.predict(x_test)\n",
    "ypred = y_pred.reshape(len(y_pred), )\n",
    "y_pred = np.round(y_pred)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c22e10f",
   "metadata": {},
   "source": [
    "# Model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d39e640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_7 (Conv1D)           (None, 384, 128)          4224      \n",
      "                                                                 \n",
      " conv1d_8 (Conv1D)           (None, 384, 128)          524416    \n",
      "                                                                 \n",
      " conv1d_9 (Conv1D)           (None, 384, 128)          524416    \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 49152)             0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 64)                3145792   \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,200,961\n",
      "Trainable params: 4,200,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "\n",
    "# model1.add(Input(shape=(x_train.shape[1],1)))\n",
    "\n",
    "model2.add(Conv1D(128, 32, padding='same', activation=tf.keras.layers.LeakyReLU(alpha=.1), input_shape=[384, 1]))\n",
    "model2.add(Conv1D(128, 32, padding='same', activation=tf.keras.layers.LeakyReLU(alpha=.1)))\n",
    "model2.add(Conv1D(128, 32, padding='same', activation=tf.keras.layers.LeakyReLU(alpha=.1)))\n",
    "\n",
    "model2.add(Flatten())\n",
    "\n",
    "model2.add(Dense(64, activation='relu'))\n",
    "model2.add(Dense(32, activation='relu'))\n",
    "model2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model2.compile(optimizer=Adam(learning_rate=.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "31fc5346",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "19/19 - 1s - loss: 0.6986 - accuracy: 0.5233 - 1s/epoch - 53ms/step\n",
      "Epoch 2/20\n",
      "19/19 - 1s - loss: 0.6968 - accuracy: 0.5167 - 521ms/epoch - 27ms/step\n",
      "Epoch 3/20\n",
      "19/19 - 1s - loss: 0.7046 - accuracy: 0.4667 - 521ms/epoch - 27ms/step\n",
      "Epoch 4/20\n",
      "19/19 - 1s - loss: 0.6964 - accuracy: 0.5000 - 517ms/epoch - 27ms/step\n",
      "Epoch 5/20\n",
      "19/19 - 1s - loss: 0.6949 - accuracy: 0.4433 - 519ms/epoch - 27ms/step\n",
      "Epoch 6/20\n",
      "19/19 - 1s - loss: 0.6941 - accuracy: 0.5133 - 517ms/epoch - 27ms/step\n",
      "Epoch 7/20\n",
      "19/19 - 1s - loss: 0.6862 - accuracy: 0.5400 - 518ms/epoch - 27ms/step\n",
      "Epoch 8/20\n",
      "19/19 - 1s - loss: 0.6710 - accuracy: 0.6167 - 517ms/epoch - 27ms/step\n",
      "Epoch 9/20\n",
      "19/19 - 1s - loss: 0.7159 - accuracy: 0.6033 - 517ms/epoch - 27ms/step\n",
      "Epoch 10/20\n",
      "19/19 - 1s - loss: 1.2342 - accuracy: 0.5200 - 517ms/epoch - 27ms/step\n",
      "Epoch 11/20\n",
      "19/19 - 1s - loss: 0.7924 - accuracy: 0.5300 - 515ms/epoch - 27ms/step\n",
      "Epoch 12/20\n",
      "19/19 - 1s - loss: 0.9245 - accuracy: 0.4867 - 517ms/epoch - 27ms/step\n",
      "Epoch 13/20\n",
      "19/19 - 1s - loss: 0.7203 - accuracy: 0.5567 - 541ms/epoch - 28ms/step\n",
      "Epoch 14/20\n",
      "19/19 - 1s - loss: 0.6696 - accuracy: 0.6000 - 546ms/epoch - 29ms/step\n",
      "Epoch 15/20\n",
      "19/19 - 1s - loss: 0.6676 - accuracy: 0.5933 - 517ms/epoch - 27ms/step\n",
      "Epoch 16/20\n",
      "19/19 - 1s - loss: 0.6665 - accuracy: 0.6167 - 516ms/epoch - 27ms/step\n",
      "Epoch 17/20\n",
      "19/19 - 1s - loss: 0.6325 - accuracy: 0.6267 - 532ms/epoch - 28ms/step\n",
      "Epoch 18/20\n",
      "19/19 - 1s - loss: 0.6260 - accuracy: 0.6767 - 517ms/epoch - 27ms/step\n",
      "Epoch 19/20\n",
      "19/19 - 1s - loss: 0.6529 - accuracy: 0.6267 - 518ms/epoch - 27ms/step\n",
      "Epoch 20/20\n",
      "19/19 - 1s - loss: 0.6122 - accuracy: 0.6533 - 520ms/epoch - 27ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2c08f00b50>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(x_train_tmp, y_train.reshape(-1,1), epochs=20, batch_size=16, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "68a4edae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 9ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.56      0.57       100\n",
      "           1       0.58      0.60      0.59       100\n",
      "\n",
      "    accuracy                           0.58       200\n",
      "   macro avg       0.58      0.58      0.58       200\n",
      "weighted avg       0.58      0.58      0.58       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model2.predict(x_test)\n",
    "ypred = y_pred.reshape(len(y_pred), )\n",
    "y_pred = np.round(y_pred)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "3eb33e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_tmp = tf.expand_dims(x_test.copy(), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c91ab451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 98ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.62      0.59       100\n",
      "           1       0.57      0.51      0.54       100\n",
      "\n",
      "    accuracy                           0.56       200\n",
      "   macro avg       0.57      0.56      0.56       200\n",
      "weighted avg       0.57      0.56      0.56       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model2.predict(x_test_tmp)\n",
    "ypred = y_pred.reshape(len(y_pred), )\n",
    "y_pred = np.round(y_pred)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c04c9c",
   "metadata": {},
   "source": [
    "# Model3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc2e672",
   "metadata": {},
   "source": [
    "# More Conv1D layers. No Dense layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f5d0a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_10 (Conv1D)          (None, 384, 128)          4224      \n",
      "                                                                 \n",
      " conv1d_11 (Conv1D)          (None, 384, 128)          524416    \n",
      "                                                                 \n",
      " conv1d_12 (Conv1D)          (None, 384, 128)          524416    \n",
      "                                                                 \n",
      " conv1d_13 (Conv1D)          (None, 384, 128)          524416    \n",
      "                                                                 \n",
      " conv1d_14 (Conv1D)          (None, 384, 128)          524416    \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 49152)             0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 1)                 49153     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,151,041\n",
      "Trainable params: 2,151,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3 = Sequential()\n",
    "\n",
    "# model1.add(Input(shape=(x_train.shape[1],1)))\n",
    "\n",
    "model3.add(Conv1D(128, 32, padding='same', activation=tf.keras.layers.LeakyReLU(alpha=.1), input_shape=[384, 1]))\n",
    "model3.add(Conv1D(128, 32, padding='same', activation=tf.keras.layers.LeakyReLU(alpha=.1)))\n",
    "model3.add(Conv1D(128, 32, padding='same', activation=tf.keras.layers.LeakyReLU(alpha=.1)))\n",
    "model3.add(Conv1D(128, 32, padding='same', activation=tf.keras.layers.LeakyReLU(alpha=.1)))\n",
    "model3.add(Conv1D(128, 32, padding='same', activation=tf.keras.layers.LeakyReLU(alpha=.1)))\n",
    "\n",
    "model3.add(Flatten())\n",
    "\n",
    "# model3.add(Dense(64, activation='relu'))\n",
    "# model3.add(Dense(32, activation='relu'))\n",
    "model3.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model3.compile(optimizer=Adam(learning_rate=.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e0027f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "19/19 - 1s - loss: 0.7168 - accuracy: 0.4867 - 1s/epoch - 75ms/step\n",
      "Epoch 2/20\n",
      "19/19 - 1s - loss: 0.6936 - accuracy: 0.4733 - 932ms/epoch - 49ms/step\n",
      "Epoch 3/20\n",
      "19/19 - 1s - loss: 0.7006 - accuracy: 0.5367 - 918ms/epoch - 48ms/step\n",
      "Epoch 4/20\n",
      "19/19 - 1s - loss: 0.7949 - accuracy: 0.5233 - 926ms/epoch - 49ms/step\n",
      "Epoch 5/20\n",
      "19/19 - 1s - loss: 0.6963 - accuracy: 0.5333 - 898ms/epoch - 47ms/step\n",
      "Epoch 6/20\n",
      "19/19 - 1s - loss: 0.7005 - accuracy: 0.4933 - 937ms/epoch - 49ms/step\n",
      "Epoch 7/20\n",
      "19/19 - 1s - loss: 0.7260 - accuracy: 0.5133 - 935ms/epoch - 49ms/step\n",
      "Epoch 8/20\n",
      "19/19 - 1s - loss: 0.7085 - accuracy: 0.5533 - 929ms/epoch - 49ms/step\n",
      "Epoch 9/20\n",
      "19/19 - 1s - loss: 0.7218 - accuracy: 0.4400 - 891ms/epoch - 47ms/step\n",
      "Epoch 10/20\n",
      "19/19 - 1s - loss: 0.6938 - accuracy: 0.5333 - 886ms/epoch - 47ms/step\n",
      "Epoch 11/20\n",
      "19/19 - 1s - loss: 0.6958 - accuracy: 0.5067 - 889ms/epoch - 47ms/step\n",
      "Epoch 12/20\n",
      "19/19 - 1s - loss: 0.6754 - accuracy: 0.5600 - 889ms/epoch - 47ms/step\n",
      "Epoch 13/20\n",
      "19/19 - 1s - loss: 7.1802 - accuracy: 0.5000 - 890ms/epoch - 47ms/step\n",
      "Epoch 14/20\n",
      "19/19 - 1s - loss: 37.0239 - accuracy: 0.5400 - 884ms/epoch - 47ms/step\n",
      "Epoch 15/20\n",
      "19/19 - 1s - loss: 56.5828 - accuracy: 0.5000 - 890ms/epoch - 47ms/step\n",
      "Epoch 16/20\n",
      "19/19 - 1s - loss: 4.8108 - accuracy: 0.5200 - 889ms/epoch - 47ms/step\n",
      "Epoch 17/20\n",
      "19/19 - 1s - loss: 1.5798 - accuracy: 0.4833 - 888ms/epoch - 47ms/step\n",
      "Epoch 18/20\n",
      "19/19 - 1s - loss: 0.8873 - accuracy: 0.5267 - 886ms/epoch - 47ms/step\n",
      "Epoch 19/20\n",
      "19/19 - 1s - loss: 1.0659 - accuracy: 0.5333 - 888ms/epoch - 47ms/step\n",
      "Epoch 20/20\n",
      "19/19 - 1s - loss: 0.9977 - accuracy: 0.5333 - 885ms/epoch - 47ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2c0656ccd0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(x_train_tmp, y_train.reshape(-1,1), epochs=20, batch_size=16, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "24d7646d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 15ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.49      0.51       100\n",
      "           1       0.53      0.57      0.55       100\n",
      "\n",
      "    accuracy                           0.53       200\n",
      "   macro avg       0.53      0.53      0.53       200\n",
      "weighted avg       0.53      0.53      0.53       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model3.predict(x_test)\n",
    "ypred = y_pred.reshape(len(y_pred), )\n",
    "y_pred = np.round(y_pred)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab872ba",
   "metadata": {},
   "source": [
    "# Removing the Dense layers, makes the netowrk unable to learn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe90f01",
   "metadata": {},
   "source": [
    "# Model4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d125b4",
   "metadata": {},
   "source": [
    "# One Conv1D layer, more dense layers. Epochs=50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f65fe675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_17 (Conv1D)          (None, 384, 128)          4224      \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 49152)             0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 128)               6291584   \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,306,177\n",
      "Trainable params: 6,306,177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model4 = Sequential()\n",
    "\n",
    "# model1.add(Input(shape=(x_train.shape[1],1)))\n",
    "\n",
    "model4.add(Conv1D(128, 32, padding='same', activation=tf.keras.layers.LeakyReLU(alpha=.1), input_shape=[384, 1]))\n",
    "\n",
    "model4.add(Flatten())\n",
    "\n",
    "model4.add(Dense(128, activation='relu'))\n",
    "model4.add(Dense(64, activation='relu'))\n",
    "model4.add(Dense(32, activation='relu'))\n",
    "model4.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model4.compile(optimizer=Adam(learning_rate=.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1eaf4138",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "19/19 - 1s - loss: 0.6920 - accuracy: 0.5300 - 533ms/epoch - 28ms/step\n",
      "Epoch 2/50\n",
      "19/19 - 0s - loss: 0.6242 - accuracy: 0.7067 - 146ms/epoch - 8ms/step\n",
      "Epoch 3/50\n",
      "19/19 - 0s - loss: 0.5655 - accuracy: 0.7233 - 142ms/epoch - 7ms/step\n",
      "Epoch 4/50\n",
      "19/19 - 0s - loss: 0.4923 - accuracy: 0.7933 - 141ms/epoch - 7ms/step\n",
      "Epoch 5/50\n",
      "19/19 - 0s - loss: 0.3221 - accuracy: 0.8800 - 141ms/epoch - 7ms/step\n",
      "Epoch 6/50\n",
      "19/19 - 0s - loss: 0.2216 - accuracy: 0.9200 - 139ms/epoch - 7ms/step\n",
      "Epoch 7/50\n",
      "19/19 - 0s - loss: 0.1501 - accuracy: 0.9433 - 147ms/epoch - 8ms/step\n",
      "Epoch 8/50\n",
      "19/19 - 0s - loss: 0.0854 - accuracy: 0.9700 - 140ms/epoch - 7ms/step\n",
      "Epoch 9/50\n",
      "19/19 - 0s - loss: 0.0350 - accuracy: 0.9900 - 134ms/epoch - 7ms/step\n",
      "Epoch 10/50\n",
      "19/19 - 0s - loss: 0.0137 - accuracy: 1.0000 - 136ms/epoch - 7ms/step\n",
      "Epoch 11/50\n",
      "19/19 - 0s - loss: 0.0040 - accuracy: 1.0000 - 139ms/epoch - 7ms/step\n",
      "Epoch 12/50\n",
      "19/19 - 0s - loss: 0.0015 - accuracy: 1.0000 - 134ms/epoch - 7ms/step\n",
      "Epoch 13/50\n",
      "19/19 - 0s - loss: 9.4609e-04 - accuracy: 1.0000 - 137ms/epoch - 7ms/step\n",
      "Epoch 14/50\n",
      "19/19 - 0s - loss: 6.5270e-04 - accuracy: 1.0000 - 136ms/epoch - 7ms/step\n",
      "Epoch 15/50\n",
      "19/19 - 0s - loss: 4.8165e-04 - accuracy: 1.0000 - 140ms/epoch - 7ms/step\n",
      "Epoch 16/50\n",
      "19/19 - 0s - loss: 4.0368e-04 - accuracy: 1.0000 - 141ms/epoch - 7ms/step\n",
      "Epoch 17/50\n",
      "19/19 - 0s - loss: 3.4602e-04 - accuracy: 1.0000 - 139ms/epoch - 7ms/step\n",
      "Epoch 18/50\n",
      "19/19 - 0s - loss: 2.9930e-04 - accuracy: 1.0000 - 138ms/epoch - 7ms/step\n",
      "Epoch 19/50\n",
      "19/19 - 0s - loss: 2.6155e-04 - accuracy: 1.0000 - 146ms/epoch - 8ms/step\n",
      "Epoch 20/50\n",
      "19/19 - 0s - loss: 2.3542e-04 - accuracy: 1.0000 - 140ms/epoch - 7ms/step\n",
      "Epoch 21/50\n",
      "19/19 - 0s - loss: 2.0587e-04 - accuracy: 1.0000 - 141ms/epoch - 7ms/step\n",
      "Epoch 22/50\n",
      "19/19 - 0s - loss: 1.8653e-04 - accuracy: 1.0000 - 140ms/epoch - 7ms/step\n",
      "Epoch 23/50\n",
      "19/19 - 0s - loss: 1.7275e-04 - accuracy: 1.0000 - 139ms/epoch - 7ms/step\n",
      "Epoch 24/50\n",
      "19/19 - 0s - loss: 1.5247e-04 - accuracy: 1.0000 - 138ms/epoch - 7ms/step\n",
      "Epoch 25/50\n",
      "19/19 - 0s - loss: 1.3780e-04 - accuracy: 1.0000 - 138ms/epoch - 7ms/step\n",
      "Epoch 26/50\n",
      "19/19 - 0s - loss: 1.2596e-04 - accuracy: 1.0000 - 139ms/epoch - 7ms/step\n",
      "Epoch 27/50\n",
      "19/19 - 0s - loss: 1.1610e-04 - accuracy: 1.0000 - 141ms/epoch - 7ms/step\n",
      "Epoch 28/50\n",
      "19/19 - 0s - loss: 1.0724e-04 - accuracy: 1.0000 - 144ms/epoch - 8ms/step\n",
      "Epoch 29/50\n",
      "19/19 - 0s - loss: 9.9213e-05 - accuracy: 1.0000 - 145ms/epoch - 8ms/step\n",
      "Epoch 30/50\n",
      "19/19 - 0s - loss: 9.1656e-05 - accuracy: 1.0000 - 142ms/epoch - 7ms/step\n",
      "Epoch 31/50\n",
      "19/19 - 0s - loss: 8.5081e-05 - accuracy: 1.0000 - 144ms/epoch - 8ms/step\n",
      "Epoch 32/50\n",
      "19/19 - 0s - loss: 7.9082e-05 - accuracy: 1.0000 - 156ms/epoch - 8ms/step\n",
      "Epoch 33/50\n",
      "19/19 - 0s - loss: 7.4445e-05 - accuracy: 1.0000 - 141ms/epoch - 7ms/step\n",
      "Epoch 34/50\n",
      "19/19 - 0s - loss: 6.8913e-05 - accuracy: 1.0000 - 139ms/epoch - 7ms/step\n",
      "Epoch 35/50\n",
      "19/19 - 0s - loss: 6.4396e-05 - accuracy: 1.0000 - 138ms/epoch - 7ms/step\n",
      "Epoch 36/50\n",
      "19/19 - 0s - loss: 6.0737e-05 - accuracy: 1.0000 - 140ms/epoch - 7ms/step\n",
      "Epoch 37/50\n",
      "19/19 - 0s - loss: 5.6774e-05 - accuracy: 1.0000 - 143ms/epoch - 8ms/step\n",
      "Epoch 38/50\n",
      "19/19 - 0s - loss: 5.3528e-05 - accuracy: 1.0000 - 142ms/epoch - 7ms/step\n",
      "Epoch 39/50\n",
      "19/19 - 0s - loss: 5.0694e-05 - accuracy: 1.0000 - 145ms/epoch - 8ms/step\n",
      "Epoch 40/50\n",
      "19/19 - 0s - loss: 4.7831e-05 - accuracy: 1.0000 - 147ms/epoch - 8ms/step\n",
      "Epoch 41/50\n",
      "19/19 - 0s - loss: 4.5459e-05 - accuracy: 1.0000 - 143ms/epoch - 8ms/step\n",
      "Epoch 42/50\n",
      "19/19 - 0s - loss: 4.3189e-05 - accuracy: 1.0000 - 146ms/epoch - 8ms/step\n",
      "Epoch 43/50\n",
      "19/19 - 0s - loss: 4.0605e-05 - accuracy: 1.0000 - 155ms/epoch - 8ms/step\n",
      "Epoch 44/50\n",
      "19/19 - 0s - loss: 3.8704e-05 - accuracy: 1.0000 - 155ms/epoch - 8ms/step\n",
      "Epoch 45/50\n",
      "19/19 - 0s - loss: 3.6888e-05 - accuracy: 1.0000 - 156ms/epoch - 8ms/step\n",
      "Epoch 46/50\n",
      "19/19 - 0s - loss: 3.5148e-05 - accuracy: 1.0000 - 158ms/epoch - 8ms/step\n",
      "Epoch 47/50\n",
      "19/19 - 0s - loss: 3.3476e-05 - accuracy: 1.0000 - 154ms/epoch - 8ms/step\n",
      "Epoch 48/50\n",
      "19/19 - 0s - loss: 3.2233e-05 - accuracy: 1.0000 - 145ms/epoch - 8ms/step\n",
      "Epoch 49/50\n",
      "19/19 - 0s - loss: 3.0600e-05 - accuracy: 1.0000 - 148ms/epoch - 8ms/step\n",
      "Epoch 50/50\n",
      "19/19 - 0s - loss: 2.9216e-05 - accuracy: 1.0000 - 144ms/epoch - 8ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2be8118790>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.fit(x_train_tmp, y_train.reshape(-1,1), epochs=50, batch_size=16, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "493fda69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.58      0.59       100\n",
      "           1       0.60      0.63      0.61       100\n",
      "\n",
      "    accuracy                           0.60       200\n",
      "   macro avg       0.61      0.60      0.60       200\n",
      "weighted avg       0.61      0.60      0.60       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model4.predict(x_test)\n",
    "ypred = y_pred.reshape(len(y_pred), )\n",
    "y_pred = np.round(y_pred)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cce59a9",
   "metadata": {},
   "source": [
    "# Increasing the number of epochs does not improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db43b8a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8072ef03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42859a88",
   "metadata": {},
   "source": [
    "# Model5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bacad0",
   "metadata": {},
   "source": [
    "# Adding LSTM layer to model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3afaf65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-13 11:05:37.000017: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-08-13 11:05:37.000073: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (petar-X580VD): /proc/driver/nvidia/version does not exist\n",
      "2022-08-13 11:05:37.072842: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 384, 128)          4224      \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 128)               131584    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 146,177\n",
      "Trainable params: 146,177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model5 = Sequential()\n",
    "\n",
    "# model1.add(Input(shape=(x_train.shape[1],1)))\n",
    "\n",
    "model5.add(Conv1D(128, 32, padding='same', activation=tf.keras.layers.LeakyReLU(alpha=.1), input_shape=[384, 1]))\n",
    "\n",
    "model5.add(LSTM(128))\n",
    "\n",
    "model5.add(Flatten())\n",
    "\n",
    "\n",
    "\n",
    "model5.add(Dense(64, activation='relu'))\n",
    "model5.add(Dense(32, activation='relu'))\n",
    "model5.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model5.compile(optimizer=Adam(learning_rate=.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "be0d432d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "19/19 - 2s - loss: 0.6940 - accuracy: 0.4933 - 2s/epoch - 96ms/step\n",
      "Epoch 2/20\n",
      "19/19 - 0s - loss: 0.6934 - accuracy: 0.5000 - 387ms/epoch - 20ms/step\n",
      "Epoch 3/20\n",
      "19/19 - 0s - loss: 0.6933 - accuracy: 0.5000 - 387ms/epoch - 20ms/step\n",
      "Epoch 4/20\n",
      "19/19 - 0s - loss: 0.6931 - accuracy: 0.5000 - 378ms/epoch - 20ms/step\n",
      "Epoch 5/20\n",
      "19/19 - 0s - loss: 0.6932 - accuracy: 0.5000 - 379ms/epoch - 20ms/step\n",
      "Epoch 6/20\n",
      "19/19 - 0s - loss: 0.6932 - accuracy: 0.5000 - 406ms/epoch - 21ms/step\n",
      "Epoch 7/20\n",
      "19/19 - 0s - loss: 0.6927 - accuracy: 0.5100 - 399ms/epoch - 21ms/step\n",
      "Epoch 8/20\n",
      "19/19 - 0s - loss: 0.6925 - accuracy: 0.5000 - 375ms/epoch - 20ms/step\n",
      "Epoch 9/20\n",
      "19/19 - 0s - loss: 0.6897 - accuracy: 0.5467 - 392ms/epoch - 21ms/step\n",
      "Epoch 10/20\n",
      "19/19 - 0s - loss: 0.6870 - accuracy: 0.5533 - 377ms/epoch - 20ms/step\n",
      "Epoch 11/20\n",
      "19/19 - 0s - loss: 0.6828 - accuracy: 0.5800 - 384ms/epoch - 20ms/step\n",
      "Epoch 12/20\n",
      "19/19 - 0s - loss: 0.6778 - accuracy: 0.5833 - 392ms/epoch - 21ms/step\n",
      "Epoch 13/20\n",
      "19/19 - 0s - loss: 0.6916 - accuracy: 0.5000 - 396ms/epoch - 21ms/step\n",
      "Epoch 14/20\n",
      "19/19 - 0s - loss: 0.6883 - accuracy: 0.5300 - 393ms/epoch - 21ms/step\n",
      "Epoch 15/20\n",
      "19/19 - 0s - loss: 0.6840 - accuracy: 0.5633 - 375ms/epoch - 20ms/step\n",
      "Epoch 16/20\n",
      "19/19 - 0s - loss: 0.6612 - accuracy: 0.6333 - 384ms/epoch - 20ms/step\n",
      "Epoch 17/20\n",
      "19/19 - 0s - loss: 0.6647 - accuracy: 0.5967 - 375ms/epoch - 20ms/step\n",
      "Epoch 18/20\n",
      "19/19 - 0s - loss: 0.6532 - accuracy: 0.6400 - 382ms/epoch - 20ms/step\n",
      "Epoch 19/20\n",
      "19/19 - 0s - loss: 0.6475 - accuracy: 0.6533 - 386ms/epoch - 20ms/step\n",
      "Epoch 20/20\n",
      "19/19 - 0s - loss: 0.6455 - accuracy: 0.6300 - 396ms/epoch - 21ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2a347f63d0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5.fit(x_train_tmp, y_train.reshape(-1,1), epochs=20, batch_size=16, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "73d20e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 12ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.71      0.66       100\n",
      "           1       0.66      0.56      0.61       100\n",
      "\n",
      "    accuracy                           0.64       200\n",
      "   macro avg       0.64      0.64      0.63       200\n",
      "weighted avg       0.64      0.64      0.63       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model5.predict(x_test)\n",
    "ypred = y_pred.reshape(len(y_pred), )\n",
    "y_pred = np.round(y_pred)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ade76c",
   "metadata": {},
   "source": [
    "# Adding one LSTM layer does not improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a86325",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed59ee8c",
   "metadata": {},
   "source": [
    "# Model6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c74e12",
   "metadata": {},
   "source": [
    "# Adding multiple LSTM layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3d79cde7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_28 (Conv1D)          (None, 384, 128)          4224      \n",
      "                                                                 \n",
      " lstm_14 (LSTM)              (None, 384, 128)          131584    \n",
      "                                                                 \n",
      " lstm_15 (LSTM)              (None, 384, 64)           49408     \n",
      "                                                                 \n",
      " lstm_16 (LSTM)              (None, 32)                12416     \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 128)               4224      \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 212,225\n",
      "Trainable params: 212,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model6 = Sequential()\n",
    "\n",
    "# model1.add(Input(shape=(x_train.shape[1],1)))\n",
    "\n",
    "model6.add(Conv1D(128, 32, padding='same', activation=tf.keras.layers.LeakyReLU(alpha=.1), input_shape=[384, 1]))\n",
    "\n",
    "model6.add(LSTM(128, return_sequences=True))\n",
    "model6.add(LSTM(64, return_sequences=True))\n",
    "model6.add(LSTM(32))\n",
    "\n",
    "# model6.add(Flatten())\n",
    "\n",
    "model6.add(Dense(128, activation='relu'))\n",
    "model6.add(Dense(64, activation='relu'))\n",
    "model6.add(Dense(32, activation='relu'))\n",
    "model6.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model6.compile(optimizer=Adam(learning_rate=.01), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dcc01400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "19/19 - 4s - loss: 0.7008 - accuracy: 0.5200 - 4s/epoch - 224ms/step\n",
      "Epoch 2/20\n",
      "19/19 - 1s - loss: 0.6945 - accuracy: 0.5000 - 816ms/epoch - 43ms/step\n",
      "Epoch 3/20\n",
      "19/19 - 1s - loss: 0.6948 - accuracy: 0.4533 - 787ms/epoch - 41ms/step\n",
      "Epoch 4/20\n",
      "19/19 - 1s - loss: 0.6944 - accuracy: 0.5000 - 817ms/epoch - 43ms/step\n",
      "Epoch 5/20\n",
      "19/19 - 1s - loss: 0.6939 - accuracy: 0.4533 - 791ms/epoch - 42ms/step\n",
      "Epoch 6/20\n",
      "19/19 - 1s - loss: 0.6959 - accuracy: 0.5000 - 792ms/epoch - 42ms/step\n",
      "Epoch 7/20\n",
      "19/19 - 1s - loss: 0.6938 - accuracy: 0.5000 - 851ms/epoch - 45ms/step\n",
      "Epoch 8/20\n",
      "19/19 - 1s - loss: 0.6936 - accuracy: 0.4933 - 798ms/epoch - 42ms/step\n",
      "Epoch 9/20\n",
      "19/19 - 1s - loss: 0.6934 - accuracy: 0.4933 - 823ms/epoch - 43ms/step\n",
      "Epoch 10/20\n",
      "19/19 - 1s - loss: 0.6937 - accuracy: 0.4533 - 778ms/epoch - 41ms/step\n",
      "Epoch 11/20\n",
      "19/19 - 1s - loss: 0.6938 - accuracy: 0.4667 - 817ms/epoch - 43ms/step\n",
      "Epoch 12/20\n",
      "19/19 - 1s - loss: 0.6936 - accuracy: 0.4800 - 850ms/epoch - 45ms/step\n",
      "Epoch 13/20\n",
      "19/19 - 1s - loss: 0.6933 - accuracy: 0.5000 - 800ms/epoch - 42ms/step\n",
      "Epoch 14/20\n",
      "19/19 - 1s - loss: 0.6938 - accuracy: 0.4333 - 787ms/epoch - 41ms/step\n",
      "Epoch 15/20\n",
      "19/19 - 1s - loss: 0.6965 - accuracy: 0.4333 - 816ms/epoch - 43ms/step\n",
      "Epoch 16/20\n",
      "19/19 - 1s - loss: 0.6933 - accuracy: 0.5000 - 800ms/epoch - 42ms/step\n",
      "Epoch 17/20\n",
      "19/19 - 1s - loss: 0.6936 - accuracy: 0.5000 - 834ms/epoch - 44ms/step\n",
      "Epoch 18/20\n",
      "19/19 - 1s - loss: 0.6934 - accuracy: 0.5000 - 793ms/epoch - 42ms/step\n",
      "Epoch 19/20\n",
      "19/19 - 1s - loss: 0.6935 - accuracy: 0.5000 - 809ms/epoch - 43ms/step\n",
      "Epoch 20/20\n",
      "19/19 - 1s - loss: 0.6935 - accuracy: 0.5000 - 850ms/epoch - 45ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2a3ed0eaf0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model6.fit(x_train_tmp, y_train.reshape(-1,1), epochs=20, batch_size=16, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a34a4306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 26ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "\n",
      "    accuracy                           0.50       200\n",
      "   macro avg       0.25      0.50      0.33       200\n",
      "weighted avg       0.25      0.50      0.33       200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/petar/jupyter/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/petar/jupyter/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/petar/jupyter/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = model6.predict(x_test)\n",
    "ypred = y_pred.reshape(len(y_pred), )\n",
    "y_pred = np.round(y_pred)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c65b82",
   "metadata": {},
   "source": [
    "# With more LSTM layers the network does not even learn."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

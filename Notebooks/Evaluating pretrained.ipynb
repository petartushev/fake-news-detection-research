{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa98f852",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-14 15:32:27.781606: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-14 15:32:29.125901: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-14 15:32:29.127028: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-14 15:32:29.153834: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-14 15:32:29.183882: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-14 15:32:29.184973: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-14 15:32:29.185936: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-14 15:32:35.026467: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-14 15:32:35.026858: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-14 15:32:35.027182: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-14 15:32:35.027456: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3029 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten\n",
    "from transformers import DistilBertTokenizer, TFDistilBertModel, TFBertModel, BertTokenizer, AutoModel, AutoTokenizer\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a484cb0",
   "metadata": {},
   "source": [
    "# Loading and preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f09d1251",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/petar/Fakultet/Semester 7/NLP/Datasets/fake_news/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fdf06b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.read_csv(path + 'full_train_df.csv', index_col=0)\n",
    "test = pd.read_csv(path + 'full_test_df.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bab14d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = train['tweet'].copy()\n",
    "# y_train = train['label'].copy()\n",
    "\n",
    "x_test = test['tweet'].copy()\n",
    "y_test = test['label'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503c366c",
   "metadata": {},
   "source": [
    "# Loading pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f24288cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    }
   ],
   "source": [
    "bert_base = tf.keras.models.load_model('./tmp/all/BERT_base', custom_objects={'TFBertModel': TFBertModel})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ae13a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a82f1a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa3d1e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16642bf2",
   "metadata": {},
   "source": [
    "# Evalations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8edb0bc",
   "metadata": {},
   "source": [
    "# BERT base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a7b6779",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_ids, test_attention_masks, test_outputs = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a37b8a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "bt = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "902c144a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence, label in zip(x_test, y_test):\n",
    "    \n",
    "    sentence_tokens = bt.encode_plus(sentence, max_length=240, padding='max_length', truncation=True)\n",
    "    \n",
    "    test_input_ids.append(sentence_tokens['input_ids'])\n",
    "    test_attention_masks.append(sentence_tokens['attention_mask'])\n",
    "    test_outputs.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c89424b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 914s 1s/step\n"
     ]
    }
   ],
   "source": [
    "pred = bert_base.predict(x=[np.array(test_input_ids), np.array(test_attention_masks)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89ba8713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.50      0.67     19999\n",
      "\n",
      "    accuracy                           0.50     19999\n",
      "   macro avg       0.50      0.25      0.33     19999\n",
      "weighted avg       1.00      0.50      0.67     19999\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/petar/jupyter/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/petar/jupyter/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/petar/jupyter/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "pred_round = pred.round()\n",
    "print(classification_report(pred_round, test_outputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec3a65e",
   "metadata": {},
   "source": [
    "# BERT base integrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f89a6ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    }
   ],
   "source": [
    "bert_base_integrated = tf.keras.models.load_model('./tmp/all/BERT_base_integrated', custom_objects={'TFBertModel': TFBertModel})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a99742cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_ids, test_attention_masks, test_outputs = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4af63b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "bt = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dec1d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence, label in zip(x_test, y_test):\n",
    "    \n",
    "    sentence_tokens = bt.encode_plus(sentence, max_length=240, padding='max_length', truncation=True)\n",
    "    \n",
    "    test_input_ids.append(sentence_tokens['input_ids'])\n",
    "    test_attention_masks.append(sentence_tokens['attention_mask'])\n",
    "    test_outputs.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b60b9d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 912s 1s/step\n"
     ]
    }
   ],
   "source": [
    "pred = bert_base_integrated.predict(x=[np.array(test_input_ids), np.array(test_attention_masks)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "707bc31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.50      0.67     19999\n",
      "\n",
      "    accuracy                           0.50     19999\n",
      "   macro avg       0.50      0.25      0.33     19999\n",
      "weighted avg       1.00      0.50      0.67     19999\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/petar/jupyter/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/petar/jupyter/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/petar/jupyter/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "pred_round = pred.round()\n",
    "print(classification_report(pred_round, test_outputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c886919f",
   "metadata": {},
   "source": [
    "# distilBERT base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "537785c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    }
   ],
   "source": [
    "distilBERT_base = tf.keras.models.load_model('./tmp/all/distilBERT_base', custom_objects={'TFDistilBertModel': TFDistilBertModel})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aee84c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_ids, test_attention_masks, test_outputs = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7e315ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "bt = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbcf8fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence, label in zip(x_test, y_test):\n",
    "    \n",
    "    sentence_tokens = bt.encode_plus(sentence, max_length=240, padding='max_length', truncation=True)\n",
    "    \n",
    "    test_input_ids.append(sentence_tokens['input_ids'])\n",
    "    test_attention_masks.append(sentence_tokens['attention_mask'])\n",
    "    test_outputs.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97336436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 891s 711ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = distilBERT_base.predict(x=[np.array(test_input_ids), np.array(test_attention_masks)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1a46bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.50      0.67     39998\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.50     39998\n",
      "   macro avg       0.50      0.25      0.33     39998\n",
      "weighted avg       1.00      0.50      0.67     39998\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/petar/jupyter/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/petar/jupyter/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/petar/jupyter/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "pred_round = pred.round()\n",
    "print(classification_report(pred_round, test_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d7e994",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effdba8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b66253b",
   "metadata": {},
   "source": [
    "# distilBERT base integrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43e80982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    }
   ],
   "source": [
    "distilBERT_base_integrated = tf.keras.models.load_model('./tmp/distilBERT_base_integrated', custom_objects={'TFDistilBertModel': TFDistilBertModel})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "430966af",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_ids, test_attention_masks, test_outputs = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "237124be",
   "metadata": {},
   "outputs": [],
   "source": [
    "bt = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5d75759",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence, label in zip(x_test, y_test):\n",
    "    \n",
    "    sentence_tokens = bt.encode_plus(sentence, max_length=240, padding='max_length', truncation=True)\n",
    "    \n",
    "    test_input_ids.append(sentence_tokens['input_ids'])\n",
    "    test_attention_masks.append(sentence_tokens['attention_mask'])\n",
    "    test_outputs.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37a6d407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 447s 701ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = distilBERT_base_integrated.predict(x=[np.array(test_input_ids), np.array(test_attention_masks)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7075010c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.50      0.67     19999\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.50     19999\n",
      "   macro avg       0.50      0.25      0.33     19999\n",
      "weighted avg       1.00      0.50      0.67     19999\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/petar/jupyter/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/petar/jupyter/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/petar/jupyter/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "pred_round = pred.round()\n",
    "print(classification_report(pred_round, test_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bdafa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68e3567",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
